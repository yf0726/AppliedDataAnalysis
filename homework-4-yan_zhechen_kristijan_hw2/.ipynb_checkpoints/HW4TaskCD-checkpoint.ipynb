{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4: Obsevational Studies and Applied ML\n",
    "\n",
    "### Deadline\n",
    "November 21st,11:59PM\n",
    "\n",
    "### Important notes\n",
    "\n",
    "Make sure you push on GitHub your notebook with all the cells already evaluated. Don't forget to add a textual description of your thought process, the assumptions you made, and the solution you implemented. Back up any hypotheses and claims with data, since this is an important aspect of the course. Please write all your comments in English, and use meaningful variable names in your code. Your repo should have a single notebook (plus the data files necessary) in the master branch. If there are multiple notebooks present, we will not grade anything.\n",
    "\n",
    "Use this legendary link to create your repository: [link](https://classroom.github.com/g/YXtsr0QK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your imports here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**A)** You will be working with the full US 2015 census dataset (acs2015_county_data.csv, available at https://www.kaggle.com/muonneutrino/us-census-demographic-data#acs2015_county_data.csv). Using suitable methods, determine and quantify the dependency between the percentage of self-employed citizens and per capita income across all 3,212 US counties. Do citizens in counties that have a higher percentage of self-employed people earn more per capita?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "intake = pd.read_csv(data_folder+'aac_intakes_outcomes.csv')\n",
    "intake = intake.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = intake[['animal_type','intake_year','intake_condition','intake_number','intake_type',\n",
    "                   'sex_upon_intake','age_upon_intake_(years)','time_in_shelter_days','sex_upon_outcome',\n",
    "                  'age_upon_outcome_(years)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pd.get_dummies(features)\n",
    "y = pd.get_dummies(intake['outcome_type']).Adoption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No quite sure if data standardization should be implemented after splitting training set and testing set as said by the TA. If we do not standardize test set, the accuracy will be terribly low (0.16).\n",
    "\n",
    "So I perform standardization before spliting anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_standardize = x.apply(lambda k: (k-np.mean(k))/np.std(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into 20% and 80%\n",
    "# same random seed ensuring that there is not overlapping in test set and training set\n",
    "# and x,y has same index in test set and training set\n",
    "x_te = x_standardize.sample(frac=0.2,random_state=10).reset_index().drop(columns='index')\n",
    "x_tr = x_standardize.sample(frac=0.8,random_state=10).reset_index().drop(columns='index')\n",
    "y_te = np.ravel(y.sample(frac=0.2,random_state=10).reset_index().drop(columns='index'))\n",
    "y_tr = np.ravel(y.sample(frac=0.8,random_state=10).reset_index().drop(columns='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B)** Train a logistic regression classifier on your training set. Logistic regression returns probabilities as predictions, so in order to arrive at a binary prediction, you need to put a threshold on the predicted probabilities. For the decision threshold of 0.5, present the performance of your classifier on the test set by displaying the confusion matrix. Based on the confusion matrix, manually calculate accuracy, precision, recall, and F1-score with respect to the positive and the negative class. Vary the value of the threshold in the range from 0 to 1 and visualize the value of accuracy, precision, recall, and F1-score (with respect to both classes) as a function of the threshold. The shelter has a limited capacity and has no other option but to put to sleep animals with a low probability of adoption. What metric (precision, recall, accuracy, or F1-score) and with respect to what class is the most relevant when choosing the threshold in this scenario, and why? Explain your reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C)** Reduce the number of features by selecting the subset of the k best features. Use greedy backward selection to iteratively remove features. Evaluate performance and visualize the result using 5-fold cross-validation on the training set as a function of k, where k = 1, 5, 10, 15, 20, 25, 30. Choose the optimal k and justify your choice. Interpret the top-k features and their impact on the probability of adoption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(true, predicted):\n",
    "    '''\n",
    "    Computes a confusion matrix using numpy for two np.arrays true and pred.\n",
    "    \n",
    "    Parameters:\n",
    "        true: numpy array\n",
    "        predicted: numpy array\n",
    "        \n",
    "    Return:\n",
    "        confusion matrix with K number of classes\n",
    "    '''\n",
    "    \n",
    "    K = len(np.unique(true)) # Number of classes \n",
    "    result = np.zeros((K, K))\n",
    "    \n",
    "    for i in range(len(true)):\n",
    "        result[true[i]][predicted[i]] += 1\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy: Overall, how often is the classifier correct? \n",
    "    Same for positive and negative class.\n",
    "    The formula: (TruePositives + TrueNegatives) / total\n",
    "\n",
    "    Parameters:\n",
    "        confusion_matrix: numpy array\n",
    "        \n",
    "    Return:\n",
    "        model accuracy\n",
    "    \"\"\"\n",
    "    return np.sum(np.diag(confusion_matrix))/np.sum(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(confusion_matrix, precision_class):\n",
    "    \"\"\"\n",
    "    Calculates model precision: When it predicts yes, how often is it correct? \n",
    "                                And vice versa, when it predicts no, how often is it correct?\n",
    "    \n",
    "    The formulas: TruePositives / (TruePositives + FalsePositives) or TP/predicted yes\n",
    "                  TrueNegatives / (TrueNegatives + FalseNegatives) or TN/predicted no\n",
    "\n",
    "    Parameters:\n",
    "        confusion_matrix: numpy array\n",
    "        precision_class: 0 for negative class or 1 for positive class\n",
    "        \n",
    "    Return:\n",
    "        precision for desired class\n",
    "    \"\"\"\n",
    "    # Precision for positive class\n",
    "    if precision_class == 1:\n",
    "        return confusion_matrix[1,1]/np.sum(confusion_matrix[:,1])\n",
    "    \n",
    "    # Precision for negative class\n",
    "    elif precision_class == 0:\n",
    "        if np.sum(confusion_matrix[:,0]) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return confusion_matrix[0,0]/np.sum(confusion_matrix[:,0])\n",
    "    \n",
    "    else:\n",
    "        print('Input correct value for the precision class. (0 for negative and 1 for positive class)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(confusion_matrix, precision_class):\n",
    "    \"\"\"\n",
    "    Calculates model recall: When it's actually yes, how often does it predict yes? \n",
    "                              And vice versa, when it's actually no, how often does it predict no?\n",
    "                                \n",
    "    The formulas: TruePositives / (TruePositives + FalseNegatives) or TP/actual yes\n",
    "                  TrueNegatives / (TrueNegatives + FalsePositives) or TN/actual no\n",
    "\n",
    "    Parameters:\n",
    "        confusion_matrix: numpy array\n",
    "        precision_class: 0 for negative class or 1 for positive class\n",
    "        \n",
    "    Return:\n",
    "        recall for desired class\n",
    "    \"\"\"\n",
    "    # Precision for positive class\n",
    "    if precision_class == 1:\n",
    "        return confusion_matrix[1,1]/np.sum(confusion_matrix[1,:])\n",
    "    \n",
    "    # Precision for negative class\n",
    "    elif precision_class == 0:\n",
    "        return confusion_matrix[0,0]/np.sum(confusion_matrix[0,:])\n",
    "    \n",
    "    else:\n",
    "        print('Input correct value for the precision class. (0 for negative and 1 for positive class)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(confusion_matrix, precision_class):\n",
    "    \"\"\"\n",
    "    Calculates model F1 score: Harmonic mean of precision and recall based on the confusion matrix and the precision class.\n",
    "                       \n",
    "    Parameters:\n",
    "        confusion_matrix: numpy array\n",
    "        precision_class: 0 for negative class or 1 for positive class\n",
    "        \n",
    "    Return:\n",
    "        f1_score for desired class\n",
    "    \"\"\"\n",
    "    # Precision for positive class\n",
    "    if precision_class == 1:\n",
    "        return 2 * calculate_precision(confusion_matrix,1) * calculate_recall(confusion_matrix,1)\\\n",
    "                / (calculate_precision(confusion_matrix,1) + calculate_recall(confusion_matrix,1))\n",
    "    \n",
    "    # Precision for negative class\n",
    "    elif precision_class == 0:\n",
    "        if np.sum(confusion_matrix[:,0]) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2 * calculate_precision(confusion_matrix,0) * calculate_recall(confusion_matrix,0)\\\n",
    "                / (calculate_precision(confusion_matrix,0) + calculate_recall(confusion_matrix,0))\n",
    "    \n",
    "    else:\n",
    "        print('Input correct value for the precision class. (0 for negative and 1 for positive class)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statisInfo(y_test, y_pred):\n",
    "    confusion = compute_confusion_matrix(y_test, y_pred)\n",
    "    print(\"The confusion matrix:\\n{}\\n\".format(confusion))\n",
    "    accuracy = calculate_accuracy(confusion)\n",
    "    recall = calculate_recall(confusion,1)\n",
    "    precision = calculate_precision(confusion,1)\n",
    "    F = calculate_f1_score(confusion,1)\n",
    "    print(\"accuracy: {}\\nrecall: {}\\nprecision: {}\\nF: {}\".format(accuracy, recall, precision, F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed=None):\n",
    "    \"\"\"\n",
    "    Build k indices for k-fold\n",
    "\n",
    "    :param y: numpy.array -- prediction labels\n",
    "    :param k_fold: integer -- fold number\n",
    "    :param seed: integer -- random seed, default with None\n",
    "    :return: numpy.array -- shuffled index of each data fold\n",
    "    \"\"\"\n",
    "    num_row = len(y)\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(y_, x_, k_fold,k_indices, clf,metric_method,**kwargs):\n",
    "    \"\"\"\n",
    "    cross validation\n",
    "\n",
    "    :param y_: numpy.array -- prediction labels\n",
    "    :param x_: pandas.dataframe -- features\n",
    "    :param k_indices: numpy.array -- shuffled index of each data fold\n",
    "    :param clf: method -- sklearn classifier, namely logistic or linear\n",
    "    :param k_fold: integer -- index of fold\n",
    "    :param metric_method: method -- the metric method used to calculate the performance of classifier\n",
    "    :return: np.mean(metric_list) : float -- mean of cross validation metric (can be accuracy, precision, recall,F1 score)\n",
    "    \"\"\"\n",
    "    cv_list = []\n",
    "    for k in range(k_fold):\n",
    "        test_idx = k_indices[k]\n",
    "        train_idx = list(set(np.arange(0,len(y_)))-set(k_indices[k]))\n",
    "        [x_train, y_train, x_test, y_test] = [x_.loc[train_idx], y_[train_idx], x_.loc[test_idx], y_[test_idx]]\n",
    "\n",
    "        # y_pred_prob = clf.fit(x_train, y_train).predict_proba(x_test)\n",
    "        # y_pred_tmp =(y_pred_prob[:,1] >= 0.5).astype(int)\n",
    "        y_pred_tmp = clf.fit(x_train, y_train).predict(x_test)\n",
    "        confusion_matrix = compute_confusion_matrix(y_test, y_pred_tmp)\n",
    "        metric = metric_method(confusion_matrix,**kwargs)\n",
    "        cv_list.append(metric)\n",
    "    return np.mean(cv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing greedy backward selection with k-fold cross validation \n",
    "def greedy_backward(k,x,y,k_fold,x_te,y_te,metric_method,**kwargs):\n",
    "    \"\"\"\n",
    "    to select features by recursively considering smaller and smaller sets of features.\n",
    "    the estimator is trained on the initial set of features and the importance of each feature is obtained.\n",
    "    the least important features are pruned from current set of features. \n",
    "    That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "    \"\"\"\n",
    "    clf = LogisticRegression(solver='liblinear')\n",
    "    x_drop = x\n",
    "    x_drop_te = x_te\n",
    "    names = x_drop.columns\n",
    "    drop_names = []\n",
    "    metric_tr_list = []\n",
    "    metric_te_list = []\n",
    "    k_indices = build_k_indices(y,k_fold)\n",
    "    while(len(names)>k): # looping until k features left\n",
    "        for i in range(len(names)):\n",
    "            x_drop_tmp = x_drop.drop(columns = names [i])\n",
    "            cv_metric = cross_validation(y, x_drop_tmp, k_fold,k_indices, clf,metric_method,**kwargs) # calculate the error with cross validation\n",
    "            metric_tr_list.append(cv_metric)\n",
    "        drop_idx = metric_tr_list.index(min(metric_tr_list)) # drop the feature with smal\n",
    "        print('The dropping feature is ',names[drop_idx])\n",
    "        print('The metric for training set dropping this feature ',metric_tr_list[drop_idx])\n",
    "        \n",
    "        x_drop = x_drop.drop(columns = names [drop_idx])        \n",
    "        x_drop_te = x_drop_te.drop(columns = names [drop_idx])\n",
    "        # y_pred_prob = clf.fit(x_drop, y_tr).predict_proba(x_drop_te)\n",
    "        # y_pred_tmp =(y_pred_prob[:,1] >= 0.5).astype(int)\n",
    "        y_pred_tmp = clf.fit(x_drop, y_tr).predict(x_drop_te)\n",
    "        conf_matrix = compute_confusion_matrix(y_te, y_pred_tmp)\n",
    "        metric_te = metric_method(conf_matrix,**kwargs)\n",
    "        metric_te_list.append(metric_te)\n",
    "        drop_names.append(names [drop_idx])\n",
    "        print('The metric for test set dropping this feature ', metric_te)\n",
    "        print('The confusion matrix is ')\n",
    "        print(conf_matrix)\n",
    "        \n",
    "        names = x_drop.columns\n",
    "        metric_tr_list = []\n",
    "\n",
    "    return x_drop,metric_te_list,drop_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is extremely skewed so it is not a good idea to use accuracy to test the performance of classifier.\n",
    "\n",
    "If a classifier predicts all zeros it still has accuracy of 84%.\n",
    "\n",
    "So instead of accuracy, we use recall as the metric to evaluate the performance of feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16069659953780124"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dropping feature is  time_in_shelter_days\n",
      "The metric for training set dropping this feature  0.8914531384350817\n",
      "The metric for test set dropping this feature  0.897799174690509\n",
      "The confusion matrix is \n",
      "[[5821.  283.]\n",
      " [ 460.  706.]]\n",
      "The dropping feature is  age_upon_intake_(years)\n",
      "The metric for training set dropping this feature  0.8796904557179708\n",
      "The metric for test set dropping this feature  0.8822558459422284\n",
      "The confusion matrix is \n",
      "[[5775.  329.]\n",
      " [ 527.  639.]]\n",
      "The dropping feature is  age_upon_outcome_(years)\n",
      "The metric for training set dropping this feature  0.8785210662080825\n",
      "The metric for test set dropping this feature  0.8825309491059147\n",
      "The confusion matrix is \n",
      "[[5776.  328.]\n",
      " [ 526.  640.]]\n",
      "The dropping feature is  intake_number\n",
      "The metric for training set dropping this feature  0.8783147033533962\n",
      "The metric for test set dropping this feature  0.88060522696011\n",
      "The confusion matrix is \n",
      "[[5780.  324.]\n",
      " [ 544.  622.]]\n",
      "The dropping feature is  animal_type_Bird\n",
      "The metric for training set dropping this feature  0.8783147033533962\n",
      "The metric for test set dropping this feature  0.88060522696011\n",
      "The confusion matrix is \n",
      "[[5780.  324.]\n",
      " [ 544.  622.]]\n",
      "The dropping feature is  animal_type_Dog\n",
      "The metric for training set dropping this feature  0.877695614789338\n",
      "The metric for test set dropping this feature  0.8811554332874828\n",
      "The confusion matrix is \n",
      "[[5785.  319.]\n",
      " [ 545.  621.]]\n",
      "The dropping feature is  animal_type_Cat\n",
      "The metric for training set dropping this feature  0.8571969045571798\n",
      "The metric for test set dropping this feature  0.8584594222833563\n",
      "The confusion matrix is \n",
      "[[5655.  449.]\n",
      " [ 580.  586.]]\n",
      "The dropping feature is  intake_year\n",
      "The metric for training set dropping this feature  0.8556835769561479\n",
      "The metric for test set dropping this feature  0.859697386519945\n",
      "The confusion matrix is \n",
      "[[5786.  318.]\n",
      " [ 702.  464.]]\n",
      "The dropping feature is  animal_type_Other\n",
      "The metric for training set dropping this feature  0.8555460017196903\n",
      "The metric for test set dropping this feature  0.859697386519945\n",
      "The confusion matrix is \n",
      "[[5786.  318.]\n",
      " [ 702.  464.]]\n",
      "The dropping feature is  intake_type_Euthanasia Request\n",
      "The metric for training set dropping this feature  0.855511607910576\n",
      "The metric for test set dropping this feature  0.859697386519945\n",
      "The confusion matrix is \n",
      "[[5786.  318.]\n",
      " [ 702.  464.]]\n",
      "The dropping feature is  intake_type_Stray\n",
      "The metric for training set dropping this feature  0.8552364574376613\n",
      "The metric for test set dropping this feature  0.859009628610729\n",
      "The confusion matrix is \n",
      "[[5791.  313.]\n",
      " [ 712.  454.]]\n",
      "The dropping feature is  intake_type_Public Assist\n",
      "The metric for training set dropping this feature  0.8514531384350817\n",
      "The metric for test set dropping this feature  0.8583218707015131\n",
      "The confusion matrix is \n",
      "[[5781.  323.]\n",
      " [ 707.  459.]]\n",
      "The dropping feature is  intake_type_Owner Surrender\n",
      "The metric for training set dropping this feature  0.8506620808254514\n",
      "The metric for test set dropping this feature  0.8519944979367263\n",
      "The confusion matrix is \n",
      "[[5690.  414.]\n",
      " [ 662.  504.]]\n",
      "The dropping feature is  intake_type_Wildlife\n",
      "The metric for training set dropping this feature  0.8505932932072227\n",
      "The metric for test set dropping this feature  0.8519944979367263\n",
      "The confusion matrix is \n",
      "[[5690.  414.]\n",
      " [ 662.  504.]]\n",
      "The dropping feature is  intake_condition_Aged\n",
      "The metric for training set dropping this feature  0.8505932932072227\n",
      "The metric for test set dropping this feature  0.8519944979367263\n",
      "The confusion matrix is \n",
      "[[5690.  414.]\n",
      " [ 662.  504.]]\n",
      "The dropping feature is  intake_condition_Other\n",
      "The metric for training set dropping this feature  0.8505588993981084\n",
      "The metric for test set dropping this feature  0.8519944979367263\n",
      "The confusion matrix is \n",
      "[[5690.  414.]\n",
      " [ 662.  504.]]\n",
      "The dropping feature is  intake_condition_Injured\n",
      "The metric for training set dropping this feature  0.8505588993981084\n",
      "The metric for test set dropping this feature  0.8521320495185695\n",
      "The confusion matrix is \n",
      "[[5689.  415.]\n",
      " [ 660.  506.]]\n",
      "The dropping feature is  intake_condition_Sick\n",
      "The metric for training set dropping this feature  0.8498366294067068\n",
      "The metric for test set dropping this feature  0.8511691884456671\n",
      "The confusion matrix is \n",
      "[[5700.  404.]\n",
      " [ 678.  488.]]\n",
      "The dropping feature is  intake_condition_Pregnant\n",
      "The metric for training set dropping this feature  0.8498022355975925\n",
      "The metric for test set dropping this feature  0.8511691884456671\n",
      "The confusion matrix is \n",
      "[[5701.  403.]\n",
      " [ 679.  487.]]\n",
      "The dropping feature is  sex_upon_intake_Spayed Female\n",
      "The metric for training set dropping this feature  0.8497334479793638\n",
      "The metric for test set dropping this feature  0.8511691884456671\n",
      "The confusion matrix is \n",
      "[[5701.  403.]\n",
      " [ 679.  487.]]\n",
      "The dropping feature is  sex_upon_intake_Intact Female\n",
      "The metric for training set dropping this feature  0.8476010318142734\n",
      "The metric for test set dropping this feature  0.8482806052269601\n",
      "The confusion matrix is \n",
      "[[6096.    8.]\n",
      " [1095.   71.]]\n",
      "The dropping feature is  intake_condition_Nursing\n",
      "The metric for training set dropping this feature  0.8437145313843508\n",
      "The metric for test set dropping this feature  0.842503438789546\n",
      "The confusion matrix is \n",
      "[[6071.   33.]\n",
      " [1112.   54.]]\n",
      "The dropping feature is  intake_condition_Normal\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  intake_condition_Feral\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_intake_Intact Male\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_intake_Neutered Male\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_intake_Unknown\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_outcome_Intact Female\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_outcome_Intact Male\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_outcome_Neutered Male\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_outcome_Spayed Female\n",
      "The metric for training set dropping this feature  0.8396216680997421\n",
      "The metric for test set dropping this feature  0.839614855570839\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n"
     ]
    }
   ],
   "source": [
    "x_drop,acc_te,acc_names = greedy_backward(k=1,x=x_tr,y=y_tr,k_fold=5,\n",
    "                                         x_te=x_te,y_te=y_te,metric_method=calculate_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dropping feature is  time_in_shelter_days\n",
      "The metric for training set dropping this feature  0.5885440858563556\n",
      "The metric for test set dropping this feature  0.6054888507718696\n",
      "The confusion matrix is \n",
      "[[5821.  283.]\n",
      " [ 460.  706.]]\n",
      "The dropping feature is  age_upon_intake_(years)\n",
      "The metric for training set dropping this feature  0.5451518422532458\n",
      "The metric for test set dropping this feature  0.5480274442538593\n",
      "The confusion matrix is \n",
      "[[5775.  329.]\n",
      " [ 527.  639.]]\n",
      "The dropping feature is  intake_number\n",
      "The metric for training set dropping this feature  0.5403865575270322\n",
      "The metric for test set dropping this feature  0.5497427101200686\n",
      "The confusion matrix is \n",
      "[[5779.  325.]\n",
      " [ 525.  641.]]\n",
      "The dropping feature is  age_upon_outcome_(years)\n",
      "The metric for training set dropping this feature  0.5279281123276752\n",
      "The metric for test set dropping this feature  0.5334476843910806\n",
      "The confusion matrix is \n",
      "[[5780.  324.]\n",
      " [ 544.  622.]]\n",
      "The dropping feature is  animal_type_Bird\n",
      "The metric for training set dropping this feature  0.5264030578614444\n",
      "The metric for test set dropping this feature  0.5334476843910806\n",
      "The confusion matrix is \n",
      "[[5780.  324.]\n",
      " [ 544.  622.]]\n",
      "The dropping feature is  animal_type_Dog\n",
      "The metric for training set dropping this feature  0.5259805001073706\n",
      "The metric for test set dropping this feature  0.532590051457976\n",
      "The confusion matrix is \n",
      "[[5785.  319.]\n",
      " [ 545.  621.]]\n",
      "The dropping feature is  animal_type_Cat\n",
      "The metric for training set dropping this feature  0.46769549969530877\n",
      "The metric for test set dropping this feature  0.5025728987993139\n",
      "The confusion matrix is \n",
      "[[5655.  449.]\n",
      " [ 580.  586.]]\n",
      "The dropping feature is  intake_year\n",
      "The metric for training set dropping this feature  0.39249210915591204\n",
      "The metric for test set dropping this feature  0.3979416809605489\n",
      "The confusion matrix is \n",
      "[[5786.  318.]\n",
      " [ 702.  464.]]\n",
      "The dropping feature is  animal_type_Other\n",
      "The metric for training set dropping this feature  0.39163142484071756\n",
      "The metric for test set dropping this feature  0.3979416809605489\n",
      "The confusion matrix is \n",
      "[[5786.  318.]\n",
      " [ 702.  464.]]\n",
      "The dropping feature is  intake_condition_Aged\n",
      "The metric for training set dropping this feature  0.39163142484071756\n",
      "The metric for test set dropping this feature  0.3979416809605489\n",
      "The confusion matrix is \n",
      "[[5786.  318.]\n",
      " [ 702.  464.]]\n",
      "The dropping feature is  intake_condition_Feral\n",
      "The metric for training set dropping this feature  0.39119402094880334\n",
      "The metric for test set dropping this feature  0.3979416809605489\n",
      "The confusion matrix is \n",
      "[[5786.  318.]\n",
      " [ 702.  464.]]\n",
      "The dropping feature is  intake_condition_Sick\n",
      "The metric for training set dropping this feature  0.38945110155882523\n",
      "The metric for test set dropping this feature  0.3893653516295026\n",
      "The confusion matrix is \n",
      "[[5790.  314.]\n",
      " [ 712.  454.]]\n",
      "The dropping feature is  intake_condition_Other\n",
      "The metric for training set dropping this feature  0.3894432028022986\n",
      "The metric for test set dropping this feature  0.38850771869639794\n",
      "The confusion matrix is \n",
      "[[5790.  314.]\n",
      " [ 713.  453.]]\n",
      "The dropping feature is  intake_condition_Pregnant\n",
      "The metric for training set dropping this feature  0.3894432028022986\n",
      "The metric for test set dropping this feature  0.39879931389365353\n",
      "The confusion matrix is \n",
      "[[5785.  319.]\n",
      " [ 701.  465.]]\n",
      "The dropping feature is  intake_type_Euthanasia Request\n",
      "The metric for training set dropping this feature  0.3894432028022986\n",
      "The metric for test set dropping this feature  0.3876500857632933\n",
      "The confusion matrix is \n",
      "[[5791.  313.]\n",
      " [ 714.  452.]]\n",
      "The dropping feature is  intake_type_Owner Surrender\n",
      "The metric for training set dropping this feature  0.38140087475997053\n",
      "The metric for test set dropping this feature  0.3876500857632933\n",
      "The confusion matrix is \n",
      "[[5791.  313.]\n",
      " [ 714.  452.]]\n",
      "The dropping feature is  intake_type_Public Assist\n",
      "The metric for training set dropping this feature  0.3800836409509694\n",
      "The metric for test set dropping this feature  0.3876500857632933\n",
      "The confusion matrix is \n",
      "[[5791.  313.]\n",
      " [ 714.  452.]]\n",
      "The dropping feature is  intake_condition_Injured\n",
      "The metric for training set dropping this feature  0.37775820906059726\n",
      "The metric for test set dropping this feature  0.3747855917667238\n",
      "The confusion matrix is \n",
      "[[5800.  304.]\n",
      " [ 729.  437.]]\n",
      "The dropping feature is  intake_type_Wildlife\n",
      "The metric for training set dropping this feature  0.37775820906059726\n",
      "The metric for test set dropping this feature  0.3747855917667238\n",
      "The confusion matrix is \n",
      "[[5800.  304.]\n",
      " [ 729.  437.]]\n",
      "The dropping feature is  sex_upon_intake_Intact Female\n",
      "The metric for training set dropping this feature  0.37775820906059726\n",
      "The metric for test set dropping this feature  0.3747855917667238\n",
      "The confusion matrix is \n",
      "[[5800.  304.]\n",
      " [ 729.  437.]]\n",
      "The dropping feature is  sex_upon_intake_Spayed Female\n",
      "The metric for training set dropping this feature  0.16555886727588195\n",
      "The metric for test set dropping this feature  0.3542024013722127\n",
      "The confusion matrix is \n",
      "[[5752.  352.]\n",
      " [ 753.  413.]]\n",
      "The dropping feature is  intake_type_Stray\n",
      "The metric for training set dropping this feature  0.05533428909237046\n",
      "The metric for test set dropping this feature  0.060891938250428816\n",
      "The confusion matrix is \n",
      "[[6096.    8.]\n",
      " [1095.   71.]]\n",
      "The dropping feature is  intake_condition_Normal\n",
      "The metric for training set dropping this feature  0.05533428909237046\n",
      "The metric for test set dropping this feature  0.060891938250428816\n",
      "The confusion matrix is \n",
      "[[6096.    8.]\n",
      " [1095.   71.]]\n",
      "The dropping feature is  intake_condition_Nursing\n",
      "The metric for training set dropping this feature  0.0\n",
      "The metric for test set dropping this feature  0.0\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_intake_Intact Male\n",
      "The metric for training set dropping this feature  0.0\n",
      "The metric for test set dropping this feature  0.0\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_intake_Neutered Male\n",
      "The metric for training set dropping this feature  0.0\n",
      "The metric for test set dropping this feature  0.0\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_intake_Unknown\n",
      "The metric for training set dropping this feature  0.0\n",
      "The metric for test set dropping this feature  0.0\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_outcome_Intact Female\n",
      "The metric for training set dropping this feature  0.0\n",
      "The metric for test set dropping this feature  0.0\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_outcome_Intact Male\n",
      "The metric for training set dropping this feature  0.0\n",
      "The metric for test set dropping this feature  0.0\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_outcome_Neutered Male\n",
      "The metric for training set dropping this feature  0.0\n",
      "The metric for test set dropping this feature  0.0\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n",
      "The dropping feature is  sex_upon_outcome_Spayed Female\n",
      "The metric for training set dropping this feature  0.0\n",
      "The metric for test set dropping this feature  0.0\n",
      "The confusion matrix is \n",
      "[[6104.    0.]\n",
      " [1166.    0.]]\n"
     ]
    }
   ],
   "source": [
    "x_drop,recall_te,recall_names = greedy_backward(k=1,x=x_tr,y=y_tr,k_fold=5,\n",
    "                                         x_te=x_te,y_te=y_te,metric_method=calculate_recall,precision_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_names.reverse()\n",
    "recall_te.reverse()\n",
    "acc_names.reverse()\n",
    "acc_te.reverse()\n",
    "d = {'recall feature':recall_names,\n",
    "     'recall':recall_te,\n",
    "     'accuracy feature':acc_names,\n",
    "     'accuracy':acc_te}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall feature</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy feature</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex_upon_outcome_Spayed Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sex_upon_outcome_Spayed Female</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex_upon_outcome_Neutered Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sex_upon_outcome_Neutered Male</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sex_upon_outcome_Intact Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sex_upon_outcome_Intact Male</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sex_upon_outcome_Intact Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sex_upon_outcome_Intact Female</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sex_upon_intake_Unknown</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sex_upon_intake_Unknown</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sex_upon_intake_Neutered Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sex_upon_intake_Neutered Male</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sex_upon_intake_Intact Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sex_upon_intake_Intact Male</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>intake_condition_Nursing</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>intake_condition_Feral</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>intake_condition_Normal</td>\n",
       "      <td>0.060892</td>\n",
       "      <td>intake_condition_Normal</td>\n",
       "      <td>0.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>intake_type_Stray</td>\n",
       "      <td>0.060892</td>\n",
       "      <td>intake_condition_Nursing</td>\n",
       "      <td>0.842503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sex_upon_intake_Spayed Female</td>\n",
       "      <td>0.354202</td>\n",
       "      <td>sex_upon_intake_Intact Female</td>\n",
       "      <td>0.848281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sex_upon_intake_Intact Female</td>\n",
       "      <td>0.374786</td>\n",
       "      <td>sex_upon_intake_Spayed Female</td>\n",
       "      <td>0.851169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>intake_type_Wildlife</td>\n",
       "      <td>0.374786</td>\n",
       "      <td>intake_condition_Pregnant</td>\n",
       "      <td>0.851169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>intake_condition_Injured</td>\n",
       "      <td>0.374786</td>\n",
       "      <td>intake_condition_Sick</td>\n",
       "      <td>0.851169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>intake_type_Public Assist</td>\n",
       "      <td>0.387650</td>\n",
       "      <td>intake_condition_Injured</td>\n",
       "      <td>0.852132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>intake_type_Owner Surrender</td>\n",
       "      <td>0.387650</td>\n",
       "      <td>intake_condition_Other</td>\n",
       "      <td>0.851994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>intake_type_Euthanasia Request</td>\n",
       "      <td>0.387650</td>\n",
       "      <td>intake_condition_Aged</td>\n",
       "      <td>0.851994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>intake_condition_Pregnant</td>\n",
       "      <td>0.398799</td>\n",
       "      <td>intake_type_Wildlife</td>\n",
       "      <td>0.851994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>intake_condition_Other</td>\n",
       "      <td>0.388508</td>\n",
       "      <td>intake_type_Owner Surrender</td>\n",
       "      <td>0.851994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>intake_condition_Sick</td>\n",
       "      <td>0.389365</td>\n",
       "      <td>intake_type_Public Assist</td>\n",
       "      <td>0.858322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>intake_condition_Feral</td>\n",
       "      <td>0.397942</td>\n",
       "      <td>intake_type_Stray</td>\n",
       "      <td>0.859010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>intake_condition_Aged</td>\n",
       "      <td>0.397942</td>\n",
       "      <td>intake_type_Euthanasia Request</td>\n",
       "      <td>0.859697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>animal_type_Other</td>\n",
       "      <td>0.397942</td>\n",
       "      <td>animal_type_Other</td>\n",
       "      <td>0.859697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>intake_year</td>\n",
       "      <td>0.397942</td>\n",
       "      <td>intake_year</td>\n",
       "      <td>0.859697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>animal_type_Cat</td>\n",
       "      <td>0.502573</td>\n",
       "      <td>animal_type_Cat</td>\n",
       "      <td>0.858459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>animal_type_Dog</td>\n",
       "      <td>0.532590</td>\n",
       "      <td>animal_type_Dog</td>\n",
       "      <td>0.881155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>animal_type_Bird</td>\n",
       "      <td>0.533448</td>\n",
       "      <td>animal_type_Bird</td>\n",
       "      <td>0.880605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>age_upon_outcome_(years)</td>\n",
       "      <td>0.533448</td>\n",
       "      <td>intake_number</td>\n",
       "      <td>0.880605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>intake_number</td>\n",
       "      <td>0.549743</td>\n",
       "      <td>age_upon_outcome_(years)</td>\n",
       "      <td>0.882531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>age_upon_intake_(years)</td>\n",
       "      <td>0.548027</td>\n",
       "      <td>age_upon_intake_(years)</td>\n",
       "      <td>0.882256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>time_in_shelter_days</td>\n",
       "      <td>0.605489</td>\n",
       "      <td>time_in_shelter_days</td>\n",
       "      <td>0.897799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    recall feature    recall                accuracy feature  \\\n",
       "0   sex_upon_outcome_Spayed Female  0.000000  sex_upon_outcome_Spayed Female   \n",
       "1   sex_upon_outcome_Neutered Male  0.000000  sex_upon_outcome_Neutered Male   \n",
       "2     sex_upon_outcome_Intact Male  0.000000    sex_upon_outcome_Intact Male   \n",
       "3   sex_upon_outcome_Intact Female  0.000000  sex_upon_outcome_Intact Female   \n",
       "4          sex_upon_intake_Unknown  0.000000         sex_upon_intake_Unknown   \n",
       "5    sex_upon_intake_Neutered Male  0.000000   sex_upon_intake_Neutered Male   \n",
       "6      sex_upon_intake_Intact Male  0.000000     sex_upon_intake_Intact Male   \n",
       "7         intake_condition_Nursing  0.000000          intake_condition_Feral   \n",
       "8          intake_condition_Normal  0.060892         intake_condition_Normal   \n",
       "9                intake_type_Stray  0.060892        intake_condition_Nursing   \n",
       "10   sex_upon_intake_Spayed Female  0.354202   sex_upon_intake_Intact Female   \n",
       "11   sex_upon_intake_Intact Female  0.374786   sex_upon_intake_Spayed Female   \n",
       "12            intake_type_Wildlife  0.374786       intake_condition_Pregnant   \n",
       "13        intake_condition_Injured  0.374786           intake_condition_Sick   \n",
       "14       intake_type_Public Assist  0.387650        intake_condition_Injured   \n",
       "15     intake_type_Owner Surrender  0.387650          intake_condition_Other   \n",
       "16  intake_type_Euthanasia Request  0.387650           intake_condition_Aged   \n",
       "17       intake_condition_Pregnant  0.398799            intake_type_Wildlife   \n",
       "18          intake_condition_Other  0.388508     intake_type_Owner Surrender   \n",
       "19           intake_condition_Sick  0.389365       intake_type_Public Assist   \n",
       "20          intake_condition_Feral  0.397942               intake_type_Stray   \n",
       "21           intake_condition_Aged  0.397942  intake_type_Euthanasia Request   \n",
       "22               animal_type_Other  0.397942               animal_type_Other   \n",
       "23                     intake_year  0.397942                     intake_year   \n",
       "24                 animal_type_Cat  0.502573                 animal_type_Cat   \n",
       "25                 animal_type_Dog  0.532590                 animal_type_Dog   \n",
       "26                animal_type_Bird  0.533448                animal_type_Bird   \n",
       "27        age_upon_outcome_(years)  0.533448                   intake_number   \n",
       "28                   intake_number  0.549743        age_upon_outcome_(years)   \n",
       "29         age_upon_intake_(years)  0.548027         age_upon_intake_(years)   \n",
       "30            time_in_shelter_days  0.605489            time_in_shelter_days   \n",
       "\n",
       "    accuracy  \n",
       "0   0.839615  \n",
       "1   0.839615  \n",
       "2   0.839615  \n",
       "3   0.839615  \n",
       "4   0.839615  \n",
       "5   0.839615  \n",
       "6   0.839615  \n",
       "7   0.839615  \n",
       "8   0.839615  \n",
       "9   0.842503  \n",
       "10  0.848281  \n",
       "11  0.851169  \n",
       "12  0.851169  \n",
       "13  0.851169  \n",
       "14  0.852132  \n",
       "15  0.851994  \n",
       "16  0.851994  \n",
       "17  0.851994  \n",
       "18  0.851994  \n",
       "19  0.858322  \n",
       "20  0.859010  \n",
       "21  0.859697  \n",
       "22  0.859697  \n",
       "23  0.859697  \n",
       "24  0.858459  \n",
       "25  0.881155  \n",
       "26  0.880605  \n",
       "27  0.880605  \n",
       "28  0.882531  \n",
       "29  0.882256  \n",
       "30  0.897799  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see very clear plateaus in the plotting of recall. When 25<=k<=30, the plateau is around 0.54; 10<=k25 there is a lower plateau with recall around 0.40; and for k<10, though the accuracy seems still acceptable (around 0.84), however as mentioned above, the dataset is extremly skewed and the classifier can still get 84% accuracy if it predict always 0. And this is what happens here. When k<10, the recall drops dramatically to 0, meaning that the classifier is predicting 0 all the time and is not realiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the features dropped under different k, we find out that for each plateau the dropped feature almost in same group. For example, when 25 <= k <=30, the dropped features are time_in_shelter_days, age_upon_intake_(years)\t, intake_number, age_upon_outcome_(years), animal_type_Bird, animal_type_Dog, animal_type_Cat. It seems that the animal_type and age do not influence much on the adoption.\n",
    "\n",
    "For the next plataeu, we consider this feature dropped when 10<= k < 25 is more important than features above. Surprisingly, the intake_year affects a lot the adoption. As shown below we find out the in 2016 the percentage of adoption over the total number of year intake is highest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013    1988\n",
       "2014    9298\n",
       "2015    9042\n",
       "2016    7642\n",
       "2017    7337\n",
       "2018    1041\n",
       "Name: intake_year, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intake.intake_year.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013     241\n",
       "2014    1244\n",
       "2015    1413\n",
       "2016    1565\n",
       "2017    1271\n",
       "2018     107\n",
       "Name: intake_year, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intake.loc[intake.outcome_type=='Adoption'].intake_year.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2a65d2b0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.plot(figsize=(15,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D)** Train a random forest. Use 5-fold cross-validation on the training set to fine-tune the parameters of the classifier using a grid search on the number of estimators \"n_estimators\" and the max depth of the trees \"max_depth\". For the chosen parameters, estimate the performance of your classifier on the test set by presenting the confusion matrix, accuracy, precision, recall, and F1-score with respect to both classes and compare the performance with the performance of the logistic regression. Interpret the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(para1,para2, metric):\n",
    "    \"\"\"\n",
    "    Get the best degree and lambda from the result of grid search.\n",
    "    \n",
    "    Inputs:\n",
    "        para1,para2:\n",
    "        Range of parameters in numpy.array.\n",
    "        \n",
    "        metric:\n",
    "        Metric matrix saving the valuation of performance of each combination of hyper-parameter.\n",
    "    \n",
    "    \"\"\"\n",
    "    max_row, max_col = np.unravel_index(np.argmax(metric), metric.shape)\n",
    "    return metric[max_row, max_col], para1[max_row], para2[max_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(y_, x_,para1,para2,metric_method,**kwargs):\n",
    "    \"\"\"\n",
    "    Function implements grid search.\n",
    "    \n",
    "    Inputs:\n",
    "        y,tx:\n",
    "        Label and data for model training.\n",
    "        \n",
    "        para1,para2:\n",
    "        Range of parameters in numpy.array.\n",
    "    \n",
    "    Result:\n",
    "        acc_tr,acc_te:\n",
    "        Average accuracy of 10-fold cross validation for training set and test set.\n",
    "    \"\"\"\n",
    "    metric_te = np.zeros((len(para1), len(para2)))\n",
    "    k_fold = 5\n",
    "    k_indices = build_k_indices(y_,k_fold)\n",
    "    for i in range(0,len(para1)):\n",
    "        for j in range(0,len(para2)):\n",
    "            clf = RandomForestClassifier(n_estimators=para1[i], max_depth=para2[j])\n",
    "            metric_te[i][j] = cross_validation(y_, x_, k_fold,k_indices, clf,metric_method,**kwargs)\n",
    "    return metric_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [5,10,15,20,25,30]\n",
    "max_depths = [1,4,7,10]\n",
    "grid_rf = grid_search(y_tr, x_tr,n_estimators,max_depths,calculate_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9491315563198623, 20, 10)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_parameters(n_estimators,max_depths, grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix:\n",
      "[[6041.   63.]\n",
      " [ 251.  915.]]\n",
      "\n",
      "accuracy: 0.956808803301238\n",
      "recall: 0.7847341337907375\n",
      "precision: 0.9355828220858896\n",
      "F: 0.853544776119403\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=20, max_depth=10)\n",
    "rf.fit(x_tr, y_tr)\n",
    "print_statisInfo(y_te, rf.predict(x_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
